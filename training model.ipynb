{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4JpwoyxdYcQi",
        "outputId": "cf534922-3bb7-41bb-f71b-aeb1539f0516"
      },
      "outputs": [],
      "source": [
        "!pip install segmentation-models-pytorch\n",
        "!pip install torchmetrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "duJi_yGGGtu5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as func\n",
        "import torch.optim as optim\n",
        "import torchvision.models as models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoG452pRUWjH"
      },
      "source": [
        "Завантаження датасету"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v5K0JY1CHdB5"
      },
      "outputs": [],
      "source": [
        "import kagglehub\n",
        "\n",
        "path = kagglehub.dataset_download(\"balraj98/deepglobe-road-extraction-dataset\") #завантаження датасету deepglobe-road-extraction-dataset з kaggle\n",
        "print(path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5YqXZLPGV5We"
      },
      "source": [
        "Організація даних"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7qa7uz2nHdj5"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "DATA_DIR = Path(path)\n",
        "\n",
        "metadata_df = pd.read_csv(DATA_DIR / 'metadata.csv')\n",
        "metadata_df = metadata_df[metadata_df['split'] == 'train'][['image_id', 'sat_image_path', 'mask_path']]\n",
        "metadata_df['sat_image_path'] = metadata_df['sat_image_path'].apply(lambda x: DATA_DIR / x)\n",
        "metadata_df['mask_path'] = metadata_df['mask_path'].apply(lambda x: DATA_DIR / x)\n",
        "\n",
        "\n",
        "metadata_df = metadata_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "valid_df = metadata_df.sample(frac=0.075, random_state=42)\n",
        "train_df = metadata_df.drop(valid_df.index)\n",
        "\n",
        "class_dict = pd.read_csv(DATA_DIR / 'class_dict.csv')\n",
        "class_names = class_dict['name'].tolist()\n",
        "\n",
        "\n",
        "select_classes = ['background', 'road']\n",
        "select_class_indices = [class_names.index(cls.lower()) for cls in select_classes]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dh85rFT8WYOX"
      },
      "source": [
        "Реалізація класу завантаження та попередньої обробки даних"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XPAZia1TID0n"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from torchvision import tv_tensors\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "class RoadExtractionDataset(Dataset):\n",
        "    def __init__(self, df, transform=None):\n",
        "        self.df = df\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        image = cv2.imread(str(row['sat_image_path']))\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        mask = cv2.imread(str(row['mask_path']))\n",
        "        mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)\n",
        "        mask_gray = cv2.cvtColor(mask, cv2.COLOR_RGB2GRAY)\n",
        "        output_mask = np.where(mask_gray > 128, 1, 0).astype(np.uint8)\n",
        "        output_mask = np.expand_dims(output_mask, axis=-1)\n",
        "        image = torch.from_numpy(image).permute(2, 0, 1)\n",
        "        output_mask = torch.from_numpy(output_mask).permute(2, 0, 1)\n",
        "        image = tv_tensors.Image(image)\n",
        "        output_mask = tv_tensors.Mask(output_mask)\n",
        "        if self.transform:\n",
        "            image, output_mask = self.transform((image, output_mask))\n",
        "\n",
        "        return image, output_mask"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LUPLxtQW1rh"
      },
      "source": [
        "Пайплайни препроцесингу"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jhSiXMClIM7v"
      },
      "outputs": [],
      "source": [
        "from torchvision.transforms import v2\n",
        "train_transform_cpu = v2.Compose([\n",
        "    v2.RandomHorizontalFlip(p=0.5),\n",
        "    v2.RandomVerticalFlip(p=0.5),\n",
        "    v2.RandomRotation(degrees=30),\n",
        "    v2.RandomCrop(size=(512, 512), pad_if_needed=True),\n",
        "    v2.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.0)\n",
        "])\n",
        "\n",
        "train_transform_gpu = v2.Compose([\n",
        "    v2.ToDtype(torch.float32, scale=True),\n",
        "    v2.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZaZFmTJXRXa"
      },
      "source": [
        "Ініціалізація та конфігурація завантажувачів даних"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qDUcWfmtISTV"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "cpu_num_cores = os.cpu_count()\n",
        "train_dataset = RoadExtractionDataset(train_df transform=train_transform_cpu)\n",
        "valid_dataset = RoadExtractionDataset(valid_df)\n",
        "\n",
        "BATCH_SIZE = 8\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=cpu_num_cores, pin_memory=True)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=cpu_num_cores, pin_memory=True)\n",
        "\n",
        "print(f\"Number of training batches: {len(train_loader)}\")\n",
        "print(f\"Number of validation batches: {len(valid_loader)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRmvtVnGXUQR"
      },
      "source": [
        "Програмна реалізація циклу навчання (Training Loop) та валідації моделі зі збереденням проміжних ваг та значень метрик"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "df7be07287584e69baab99f7e95ca6ff"
          ]
        },
        "id": "BY4RJdvtIuPl",
        "outputId": "44772797-d6f1-4399-8c02-c29420239eb0"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import torchmetrics\n",
        "import segmentation_models_pytorch as smp\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "import torch.compiler\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "model = smp.DeepLabV3Plus(\n",
        "    encoder_name=\"timm-mobilenetv3_large_100\",\n",
        "    encoder_weights=\"imagenet\",\n",
        "    in_channels=3,\n",
        "    classes=1,\n",
        ").to(device)\n",
        "\n",
        "print(\"Compiling the model... (Це може зайняти хвилину-дві)\")\n",
        "print(\"Model compiled successfully.\")\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss().to(device)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=1e-4)\n",
        "NUM_EPOCHS = 100\n",
        "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
        "    optimizer,\n",
        "    max_lr= 5e-4,\n",
        "    steps_per_epoch=len(train_loader),\n",
        "    epochs=NUM_EPOCHS,\n",
        "    pct_start=0.3\n",
        ")\n",
        "scaler = GradScaler()\n",
        "\n",
        "train_iou_metric = torchmetrics.JaccardIndex(task=\"binary\").to(device)\n",
        "valid_iou_metric = torchmetrics.JaccardIndex(task=\"binary\").to(device)\n",
        "\n",
        "\n",
        "train_losses = []\n",
        "valid_losses = []\n",
        "train_ious = []\n",
        "valid_ious = []\n",
        "old_valid_iou = float(\"inf\")\n",
        "num_confirmed_errors = 0\n",
        "num_constraint_errors = 5\n",
        "\n",
        "print(\"Starting training...\")\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "\n",
        "    model.train()\n",
        "    run_error = 0.0\n",
        "    train_iou_metric.reset()\n",
        "\n",
        "    for i, (images, masks) in enumerate(train_loader):\n",
        "        images = images.to(device, non_blocking=True)\n",
        "        masks = masks.to(device, non_blocking=True).float()\n",
        "        images_normalized = train_transform_gpu(images)\n",
        "        optimizer.zero_grad()\n",
        "        with autocast():\n",
        "            outputs = model(images_normalized)\n",
        "            loss = criterion(outputs, masks)\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        scheduler.step()\n",
        "\n",
        "        run_error += loss.item()\n",
        "        train_iou_metric.update(outputs.sigmoid(), masks.int())\n",
        "        print(f\"\\rEpoch {epoch + 1}/{NUM_EPOCHS}, Batch {i+1}/{len(train_loader)}, Loss: {loss.item():.4f}\", end=\"\")\n",
        "\n",
        "\n",
        "    epoch_train_loss = run_error / len(train_loader)\n",
        "    train_losses.append(epoch_train_loss)\n",
        "\n",
        "    epoch_train_iou = train_iou_metric.compute()\n",
        "    train_ious.append(epoch_train_iou.item())\n",
        "\n",
        "\n",
        "    print(f\"\\rEpoch {epoch + 1}/{NUM_EPOCHS}, Train Loss: {epoch_train_loss:.4f}, Train IoU: {epoch_train_iou:.4f}\")\n",
        "\n",
        "    torch.compiler.cudagraph_mark_step_begin()\n",
        "\n",
        "    model.eval()\n",
        "    valid_error = 0.0\n",
        "    valid_iou_metric.reset()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, masks in valid_loader:\n",
        "            images = images.to(device, non_blocking=True)\n",
        "            masks = masks.to(device, non_blocking=True).float()\n",
        "\n",
        "            images_normalized = train_transform_gpu(images)\n",
        "\n",
        "            with autocast():\n",
        "              outputs = model(images_normalized)\n",
        "              loss = criterion(outputs, masks)\n",
        "            valid_error += loss.item()\n",
        "            valid_iou_metric.update(outputs.sigmoid(), masks.int())\n",
        "            print(f\"\\rEpoch {epoch + 1}/{NUM_EPOCHS}, Batch {i+1}/{len(valid_loader)}, Loss: {loss.item():.4f}\", end=\"\")\n",
        "\n",
        "\n",
        "    epoch_valid_loss = valid_error / len(valid_loader)\n",
        "    valid_losses.append(epoch_valid_loss)\n",
        "\n",
        "    epoch_valid_iou = valid_iou_metric.compute()\n",
        "    valid_ious.append(epoch_valid_iou.item())\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{NUM_EPOCHS}, Valid Loss: {epoch_valid_loss:.4f}, Valid IoU: {epoch_valid_iou:.4f}\")\n",
        "\n",
        "\n",
        "    if abs(old_valid_iou - epoch_valid_iou) > 1e-5:\n",
        "        old_valid_iou = epoch_valid_iou\n",
        "        num_confirmed_errors = 0\n",
        "\n",
        "        checkpoint = {\n",
        "            'epoch': epoch + 1,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': epoch_valid_loss,\n",
        "            'iou': epoch_valid_iou.item()\n",
        "        }\n",
        "        torch.save(checkpoint, \"my_checkpoint.pth\")\n",
        "        print(f\"Checkpoint saved! (Improved Val Loss: {epoch_valid_loss:.4f})\")\n",
        "\n",
        "    elif num_confirmed_errors < num_constraint_errors:\n",
        "        num_confirmed_errors += 1\n",
        "        print(f\"No improvement. Early stopping counter: {num_confirmed_errors}/{num_constraint_errors}\")\n",
        "    else:\n",
        "        print(f\"Early stopping triggered at epoch {epoch + 1}.\")\n",
        "        break\n",
        "\n",
        "print(\"Training finished.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVKJVPuTYiei"
      },
      "source": [
        "Збереження значень метрик"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "n1SF49bG8JNK",
        "outputId": "8140b83d-9209-4174-fee5-21cfc45ae23a"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_11d9104b-217a-4e82-853f-fc283ad5ae9e\", \"train_loss.csv\", 8052)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "data = pd.DataFrame({\n",
        "    'train_loss': train_losses,\n",
        "    'valid_loss': valid_losses,\n",
        "    'train_iou': train_ious,\n",
        "    'valid_iou': valid_ious\n",
        "})\n",
        "data.to_csv(\"train_loss.csv\")\n",
        "files.download(\"train_loss.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFgTCVI8YoY7"
      },
      "source": [
        "Завантаження моделі"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "lm75NrrKZal0",
        "outputId": "1c3e4bfd-9b08-4a98-cbf2-9c0edd463f5c"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_47c3c45f-1348-4061-b2aa-9af6cc227e00\", \"my_checkpoint.pth\", 56926071)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "files.download(\"my_checkpoint.pth\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
